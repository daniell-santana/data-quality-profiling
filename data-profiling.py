import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import chardet
import duckdb
from ydata_profiling import ProfileReport
from openai import OpenAI
from dotenv import load_dotenv
import os
import tempfile
import base64


def duckdb_profiling(df, file_extension):
    """Gera relat√≥rio de profiling usando DuckDB para qualquer formato"""
    conn = duckdb.connect()
    
    # Cria tabela tempor√°ria a partir do DataFrame pandas
    conn.register('df_temp', df)
    
    # Coleta metadados b√°sicos
    metadata = conn.execute("""
        SELECT 
            count(*) AS total_linhas,
            (SELECT count(*) FROM information_schema.columns WHERE table_name = 'df_temp') AS total_colunas
        FROM df_temp
    """).fetchdf()
    
    # Coleta estat√≠sticas por coluna (com tratamento para nomes especiais)
    col_stats = []
    columns = conn.execute("""
        SELECT column_name 
        FROM information_schema.columns 
        WHERE table_name = 'df_temp'
    """).fetchall()
    
    for col in columns:
        col_name = col[0]
        try:
            # Usa aspas duplas para nomes de colunas com caracteres especiais
            safe_col_name = f'"{col_name}"'
            
            stats = conn.execute(f"""
                SELECT 
                    approx_count_distinct({safe_col_name})::INT AS distinct_count,
                    count({safe_col_name}) AS non_missing,
                    (1 - (count({safe_col_name}) / (SELECT count(*) FROM df_temp)) AS missing_pct,
                    min({safe_col_name}) AS min_val,
                    max({safe_col_name}) AS max_val,
                    avg(try_cast({safe_col_name} AS DOUBLE)) AS mean_val,
                    data_type AS col_type
                FROM df_temp
                CROSS JOIN (SELECT data_type FROM information_schema.columns 
                           WHERE table_name = 'df_temp' AND column_name = '{col_name}')
            """).fetchdf()
            
            col_stats.append({
                'coluna': col_name,
                'tipo': stats['col_type'][0],
                **stats.iloc[0].to_dict()
            })
        except Exception as e:
            st.warning(f"Erro ao analisar coluna {col_name}: {str(e)}")
            continue
    
    return metadata, pd.DataFrame(col_stats)

def plot_column_stats(col_stats):
    """Gera visualiza√ß√µes interativas para as colunas"""
    for _, row in col_stats.iterrows():
        with st.expander(f"**{row['coluna']}** ({row['tipo']})"):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Valores Distintos", row['distinct_count'])
                st.metric("Valores N√£o Nulos", row['non_missing'])
                st.progress(1 - row['missing_pct'], text=f"Completude: {(1 - row['missing_pct'])*100:.1f}%")
            
            with col2:
                if pd.api.types.is_numeric_dtype(row['tipo']):
                    st.metric("Valor M√≠nimo", f"{row['min_val']:.2f}")
                    st.metric("Valor M√°ximo", f"{row['max_val']:.2f}")
                    st.metric("M√©dia", f"{row['mean_val']:.2f}")

# Configura√ß√£o inicial
st.set_page_config(page_title="Profiling de Dados IA", layout="wide")
st.title("üìä Agente de Profiling de Dados")
st.markdown("""
<span style="font-size: 16px; color: #555;">
    Ferramenta inteligente para an√°lise autom√°tica da qualidade dos seus dados. Detecte
    problemas, padr√µes e anomalias, receba recomenda√ß√µes e compreenda suas bases de forma pr√°tica, visual e intuitiva.
</span>
""", unsafe_allow_html=True)

# CSS GLOBAL
st.markdown("""
<style>
    /* Importa fonte do Font Awesome */
    @import url('https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css');
            
    /* Fundo branco */
    .stApp {
        background-color: white;
    }
            
    /* Barras de progresso mais largas e azuis */
    .stProgress > div > div > div {
        background-color: #f1eef6 !important;
        height: 16px !important;
    }
            
    /* Texto geral */
    .stApp, .st-bb, .st-at, .st-ae, .st-af, .st-ag, .stMarkdown, .stAlert, 
    .stProgress, .stMetric, .st-expander, .stTextInput, .stNumberInput,
    .stSelectbox, .stSlider, .stDataFrame, .stTable {
        color: black !important;
    }
    
    /* T√≠tulos */
    h1, h2, h3, h4, h5, h6, .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 {
        color: black !important;
    }
    
    /* Links */
    a {
        color: #1f77b4 !important;
    }
</style>
""", unsafe_allow_html=True)

# Carrega chave OpenAI do .env
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Fun√ß√µes auxiliares
def detectar_encoding(arquivo):
    """Detecta o encoding do arquivo usando chardet"""
    rawdata = arquivo.read()
    resultado = chardet.detect(rawdata)
    arquivo.seek(0)  # Volta ao in√≠cio do arquivo
    return resultado['encoding']

def detectar_separador(arquivo, encoding):
    """Detecta o separador do CSV analisando as primeiras linhas"""
    conteudo = arquivo.read().decode(encoding)
    arquivo.seek(0)
    
    # Testa os separadores mais comuns
    for sep in [',', ';', '\t', '|']:
        if sep in conteudo.split('\n')[0]:
            return sep
    return ','  # Fallback padr√£o

def calcular_scores(df):
    """
    Calcula scores de qualidade de dados (1-5) para um DataFrame com base em 5 crit√©rios:
    1. Completude (valores n√£o nulos)
    2. Unicidade (registros √∫nicos)
    3. Consist√™ncia (tipos de dados)
    4. Precis√£o (outliers num√©ricos)
    5. Integridade (valores sem√¢nticos e formatos)
    """
    scores = {}
    diagnostico_colunas = {
            "Completude": [],
            "Unicidade": [],
            "Consist√™ncia": [],
            "Precis√£o": [],
            "Integridade": [],
        }
    # 1. COMPLETUDE - Verifica valores n√£o nulos
    null_pct = df.isnull().mean()
    col_completude_ruim = null_pct[null_pct > 0.3].index.tolist()
    completude_score = (1 - null_pct.mean()) * 100
    scores["Completude"] = max(1, round(completude_score / 20))
    diagnostico_colunas["Completude"] = col_completude_ruim

    # 2. UNICIDADE - Verifica registros duplicados
    if df.duplicated().mean() > 0.2:
        diagnostico_colunas["Unicidade"] = ["‚ö†Ô∏è Muitos registros duplicados"]
    unicidade_score = (1 - df.duplicated().mean()) * 100
    scores["Unicidade"] = max(1, round(unicidade_score / 20))

    # 3. CONSIST√äNCIA - Garante que o conte√∫do bate com o dtype declarado da coluna
    colunas_inconsistentes = []

    for col in df.columns:
        serie = df[col].dropna()
        if serie.empty:
            continue

        tipo = df[col].dtype
        valores = serie.astype(str).str.strip()

        # Define crit√©rios de consist√™ncia com base no tipo declarado
        if pd.api.types.is_numeric_dtype(tipo):
            # Esperado: valores realmente num√©ricos
            valores_invalidos = valores[~valores.str.match(r'^-?\d+([.,]\d+)?$', na=False)]
            if len(valores_invalidos) / len(valores) > 0.1:
                colunas_inconsistentes.append(col)

        elif pd.api.types.is_datetime64_any_dtype(tipo):
            # Esperado: valores com padr√£o de data
            date_pattern = r'^\d{2}[/-]\d{2}[/-]\d{4}$|^\d{4}[/-]\d{2}[/-]\d{2}$'
            valores_invalidos = valores[~valores.str.match(date_pattern, na=False)]
            if len(valores_invalidos) / len(valores) > 0.1:
                colunas_inconsistentes.append(col)

        elif pd.api.types.is_object_dtype(tipo):
            # Esperado: conte√∫do n√£o parecendo n√∫mero nem data (ex: "Jo√£o", "SP", etc.)
            numeros_detectados = valores.str.match(r'^-?\d+([.,]\d+)?$', na=False)
            datas_detectadas = valores.str.match(r'^\d{2}[/-]\d{2}[/-]\d{4}$|^\d{4}[/-]\d{2}[/-]\d{2}$', na=False)
            if (numeros_detectados.mean() > 0.5) or (datas_detectadas.mean() > 0.5):
                colunas_inconsistentes.append(col)

    tipo_correto_pct = 1 - (len(colunas_inconsistentes) / len(df.columns))
    scores["Consist√™ncia"] = max(1, round(tipo_correto_pct * 5))
    diagnostico_colunas["Consist√™ncia"] = colunas_inconsistentes

    # 4. PRECIS√ÉO - Detecta outliers em colunas num√©ricas
    outlier_cols = []
    numeric_cols = df.select_dtypes(include=np.number).columns
    if not numeric_cols.empty:
        outlier_score = 0
        for col in numeric_cols:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = ((df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR))
            if outliers.mean() > 0.3:
                outlier_cols.append(col)
            outlier_score += (1 - outliers.mean())
        scores["Precis√£o"] = max(1, round((outlier_score / len(numeric_cols)) * 5))
        diagnostico_colunas["Precis√£o"] = outlier_cols
    else:
        scores["Precis√£o"] = 5

    # 5. INTEGRIDADE - Verifica regras sem√¢nticas e formatos
    integridade_score = 0
    total_checks = 0
    integridade_detalhes = []

    for col in df.columns:
        col_checks = 0
        col_passes = 0
        col_problemas = []

        serie = df[col]
        col_lower = col.lower()

        # COLUNAS NUM√âRICAS
        if pd.api.types.is_numeric_dtype(serie):
            # Check 1: Negativos em campos que deveriam ser positivos
            if any(k in col_lower for k in ['valor', 'pre√ßo', 'quantidade', 'saldo']):
                if serie.min() < 0:
                    col_problemas.append("valores negativos indevidos")
                else:
                    col_passes += 1
                col_checks += 1

            # Check 2: Vari√°veis bin√°rias
            if 'bin√°rio' in col_lower or 'flag' in col_lower:
                valores = set(serie.dropna().unique())
                if not valores.issubset({0, 1}):
                    col_problemas.append("valores fora de 0/1 em campo bin√°rio")
                else:
                    col_passes += 1
                col_checks += 1

        # COLUNAS DE TEXTO
        elif pd.api.types.is_object_dtype(serie):
            sample = serie.dropna().astype(str).sample(min(100, len(serie.dropna())), random_state=42)

            # Check 3: Capitaliza√ß√£o
            if sample.str.islower().any() or sample.str.isupper().any():
                col_problemas.append("capitaliza√ß√£o inconsistente")
            else:
                col_passes += 1
            col_checks += 1

            # Check 4: C√≥digos e documentos
            if any(k in col_lower for k in ['cpf', 'cnpj', 'telefone', 'cep', 'id', 'cod', 'cd']):
                cleaned = sample.str.replace(r'\D', '', regex=True)

                expected_length = (
                    11 if 'cpf' in col_lower else
                    14 if 'cnpj' in col_lower else
                    8 if 'cep' in col_lower else
                    10 if 'telefone' in col_lower else
                    None
                )

                if any(k in col_lower for k in ['id', 'cod', 'cd']):
                    if cleaned.str.len().nunique() > 1:
                        col_problemas.append("tamanhos inconsistentes em c√≥digos/IDs")
                    else:
                        col_passes += 1
                elif expected_length:
                    if not cleaned.str.len().eq(expected_length).all():
                        col_problemas.append(f"tamanho incorreto para {col}")
                    else:
                        col_passes += 1
                col_checks += 1

            # Check 5: Datas em formato texto
            if any(k in col_lower for k in ['data', 'dt', 'date', 'nascimento', 'inicio', 'fim']):
                date_pattern = r'^\d{2}[/-]\d{2}[/-]\d{4}$|^\d{4}[/-]\d{2}[/-]\d{2}$'
                valid_dates = sample.str.contains(date_pattern, na=False)
                if valid_dates.mean() < 0.9:
                    col_problemas.append("datas fora do padr√£o")
                else:
                    col_passes += 1
                col_checks += 1

        # COLUNAS DATETIME
        elif pd.api.types.is_datetime64_any_dtype(serie):
            col_passes += 1
            col_checks += 1

        # Soma pontua√ß√£o
        if col_checks > 0:
            integridade_score += (col_passes / col_checks)
            total_checks += 1
            if col_problemas:
                integridade_detalhes.append(f"{col}: {', '.join(col_problemas)}")

    scores["Integridade"] = max(1, round((integridade_score / total_checks) * 5)) if total_checks else 5
    diagnostico_colunas["Integridade"] = integridade_detalhes

    return scores, diagnostico_colunas

# Upload de dados
uploaded_file = st.file_uploader("Carregue sua base de dados", type=["csv", "xlsx", "parquet", "json"])

# Leitura com tratamento para m√∫ltiplos formatos
if uploaded_file:
    try:
        file_name = uploaded_file.name.lower()
        file_extension = file_name.split('.')[-1]
        
        st.info(f"üìÑ Arquivo detectado: {file_name}")
        
        if file_extension == 'csv':
            encoding = detectar_encoding(uploaded_file)
            st.info(f"üî† Encoding detectado: {encoding}")
            
            separador = detectar_separador(uploaded_file, encoding)
            st.info(f"üîß Separador detectado: '{separador}'")
            
            df = pd.read_csv(uploaded_file, encoding=encoding, sep=separador)
            
        elif file_extension in ['xlsx', 'xls']:
            df = pd.read_excel(uploaded_file)
            
        elif file_extension == 'parquet':
            # Usar BytesIO para leitura em mem√≥ria
            from io import BytesIO
            df = pd.read_parquet(BytesIO(uploaded_file.getvalue()))
            
        elif file_extension == 'json':
            df = pd.read_json(uploaded_file)
            
        else:
            raise ValueError("Formato de arquivo n√£o suportado")
            
        st.success(f"‚úÖ Dados carregados com {len(df)} linhas e {len(df.columns)} colunas")
        
    except Exception as e:
        st.error(f"‚ùå Erro na leitura: {str(e)}")
        st.error("""
        Dicas para corre√ß√£o:
        1. Verificar se o arquivo n√£o est√° corrompido
        2. Para JSON: valide a estrutura em https://jsonlint.com
        3. Para Parquet: confirir a compatibilidade da vers√£o
        """)
        st.stop()

    # Se√ß√£o 1: Score de Qualidade
    st.header("üîç Diagn√≥stico de Qualidade")
    scores, diagnostico_colunas = calcular_scores(df)
    score_final = round(np.mean(list(scores.values())), 1)
    
    def plot_radar_chart(scores):
        """Gera gr√°fico de radar com os scores de qualidade"""
        categories = list(scores.keys())
        values = list(scores.values())
        
        fig = px.line_polar(
            r=values + [values[0]],  # Fechar o c√≠rculo
            theta=categories + [categories[0]],
            line_close=True,
            range_r=[0, 5],
            title="Score de Qualidade da Base (1-5)"
        )
        fig.update_traces(fill='toself', line_color='#4591b8',fillcolor='rgba(69, 145, 184, 0.5)')
        fig.update_layout(
            polar=dict(
                bgcolor='white',
                radialaxis=dict(
                    visible=True,
                    range=[0, 5],
                    tickvals=[1, 2, 3, 4, 5],
                    color='black',
                    tickfont=dict(color='black')
                )
            ),
            paper_bgcolor='white',
            plot_bgcolor='white',
            font=dict(color='black'),
            title_font=dict(color='black'),
            showlegend=False,
            height=400,
            # Movemos as margens para o layout principal
            margin=dict(t=30, b=30, l=30, r=30)
        )
        st.plotly_chart(fig, use_container_width=True)
    
    col1, col2 = st.columns([1, 2])
    with col1:
        st.subheader(f"Score Total: {score_final}/5")
        st.metric("Classifica√ß√£o", "‚≠ê" * int(score_final))
        
        st.write("### Crit√©rios:")
        
        # CSS para tooltip com √≠cone
        st.markdown("""
        <style>
        /* Tooltip com FontAwesome */
        .criteria-tooltip {
            position: relative;
            display: inline-flex;
            align-items: center;
            gap: 6px;
            margin-bottom: 5px;
        }
        .criteria-tooltip .icon {
            color: #4591b8;
            font-size: 14px;
        }
        .criteria-tooltip .tooltip-text {
            visibility: hidden;
            width: 220px;
            background-color: #2c3e50;
            color: white;
            text-align: center;
            border-radius: 6px;
            padding: 10px;
            position: absolute;
            z-index: 1000;
            bottom: 125%;
            left: 50%;
            transform: translateX(-50%);
            opacity: 0;
            transition: opacity 0.2s;
            font-size: 14px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        .criteria-tooltip:hover .tooltip-text {
            visibility: visible;
            opacity: 1;
        }
        /* Ajuste para n√£o conflitar com seu progress bar */
        .stProgress {
            margin-top: -12px !important;
            margin-bottom: 8px !important;
        }
        </style>
        """, unsafe_allow_html=True)
        
        descricoes_criterios = {
            "Completude": "Propor√ß√£o de valores preenchidos (n√£o nulos)",
            "Unicidade": "Presen√ßa de registros duplicados",
            "Consist√™ncia": "Valores batem com o tipo declarado",
            "Precis√£o": "Detec√ß√£o de outliers num√©ricos",
            "Integridade": "Formato e sem√¢ntica (CPF, datas, etc.)"
        }
        
        for criterio, valor in scores.items():
            st.markdown(f"""
            <div class="criteria-tooltip">
                {criterio}: {valor}/5
                <span class="icon"><i class="fas fa-info-circle"></i></span>
                <span class="tooltip-text">{descricoes_criterios[criterio]}</span>
            </div>
            """, unsafe_allow_html=True)
            st.progress(valor/5)

    with col2:
        st.write('<div style="margin-top:-20px;"></div>', unsafe_allow_html=True)  # Ajuste fino
        plot_radar_chart(scores)

    # Se√ß√£o 2: An√°lise da IA
    if OPENAI_API_KEY:
        st.header("üß† An√°lise e Recomenda√ß√µes da IA")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        prompt = f"""

        üß± FORMATO DA RESPOSTA (OBRIGAT√ìRIO):
        A IA **deve retornar as se√ß√µes exatamente assim**:

        [PROBLEMA IDENTIFICADO]  
        [RECOMENDA√á√ïES]  
        [MITIGA√á√ÉO]  

        üõë Se a se√ß√£o n√£o tiver conte√∫do, escreva:
        > "Nenhum problema identificado para esta se√ß√£o"

        ---

        üö® **REGRAS OBRIGAT√ìRIAS ‚Äì LEIA CUIDADOSAMENTE ANTES DE RESPONDER:**

        - ‚ùå **NUNCA** analise crit√©rios com score **maior que 3** 
        - ‚úÖ **S√ì** analise crit√©rios com **score 3, 2 ou 1**

        üõë Se um crit√©rio tiver score **4 ou 5**, **N√ÉO escreva nada sobre ele**
        üõë Mesmo que apare√ßa no diagn√≥stico, ignore se o score dele for > 3
        üîç Sempre cheque os scores antes de come√ßar a an√°lise!

        ---

        **Scores de qualidade (1-5) para esta base:**  
        {scores}

        **Crit√©rios que PODEM ser analisados (score ‚â§3):**  
        { {k: v for k, v in scores.items() if v <= 3} }

        **Diagn√≥stico por Crit√©rio (colunas com problemas detectados):**  
        {diagnostico_colunas}

        ---

        **Crit√©rios avaliados nesta an√°lise:**

        1. **Completude** ‚Äì Propor√ß√£o de valores preenchidos (n√£o nulos) nas colunas  
        2. **Unicidade** ‚Äì Presen√ßa de registros duplicados (linhas repetidas)  
        3. **Consist√™ncia** ‚Äì Verifica se os valores batem com o tipo de dado declarado (ex: n√∫mero sendo string)  
        4. **Precis√£o** ‚Äì Detecta valores extremos (outliers) em colunas num√©ricas  
        5. **Integridade** ‚Äì Avalia se os dados seguem regras de formato e sem√¢ntica (ex: CPFs, datas, flags bin√°rias, capitaliza√ß√£o(uso correto de letras mai√∫sculas e min√∫sculas em textos))

        ---

        **Contexto da base de dados:**
        - üìå N√∫mero de colunas: {len(df.columns)}
        - üìå Nomes das colunas: {list(df.columns)}
        - üìå Tipos de dados principais: {dict(df.dtypes.value_counts())}

        Voc√™ √© um analista de dados especializado em qualidade da informa√ß√£o. Responda com base nas instru√ß√µes abaixo:

        ---

        [PROBLEMA IDENTIFICADO]

        1. A partir dos nomes das colunas, identifique o **dom√≠nio da base de dados** (ex: educa√ß√£o, sa√∫de, financeiro, etc.). 

        2. **Para cada crit√©rio com scores menor ou igual a 3 (1, 2 ou 3)**:
            - üß© Explique **qual problema foi identificado**, com base no crit√©rio em quest√£o
            - üß† Utilize **apenas o Diagn√≥stico por Crit√©rio** para indicar as colunas afetadas  
            - üìä Descreva **como esse problema pode distorcer as an√°lises no dom√≠nio identificado**
            - üí° D√™ **um exemplo pr√°tico** de como isso pode impactar uma transforma√ß√£o, c√°lculos e m√©tricas

        ---

        [RECOMENDA√á√ïES]

        Para cada problema detectado:

        1. üí° Proponha uma **solu√ß√£o t√©cnica espec√≠fica** relacionada √†s colunas com problema  
        2. ‚öôÔ∏è Indique o tipo de **transforma√ß√£o ou processamento** necess√°rio (ex: padroniza√ß√£o, convers√£o, tratamento)  
        3. üìà Classifique a solu√ß√£o quanto ao **n√≠vel de complexidade**: baixo, m√©dio ou alto

        Use blocos de c√≥digo para solu√ß√µes em pandas ou SQL.

        ---

        [MITIGA√á√ÉO]

        Para prevenir recorr√™ncia dos problemas:

        1. **üîç Na Fase de Coleta (Preven√ß√£o Prim√°ria)**

            a) **Valida√ß√µes Cr√≠ticas**:  
                - ‚úì Regras de consist√™ncia para colunas relacionadas (ex: prc_aprovacao depende de alunos_previstos_LP)  
                - ‚úì Campos obrigat√≥rios em vari√°veis cr√≠ticas (ex: prof_media_LP)  
                - ‚úì Campos fechados (com regras) para c√≥digos como sg_uf e nm_uf

            b) **Restri√ß√µes de Formato**:  
                - ‚úì M√°scaras para campos como CPF, CNPJ, CEP  
                - ‚úì Faixas de valor pr√©-definidas (ex: 0‚Äì100%)  
                - ‚úì Tipagem estrita (ex: float, int, datetime)

        2. **‚öôÔ∏è Durante o Processamento (Controle de Qualidade)**

            a) **üßπ Pipeline de Limpeza**:  
                - ‚úì Padroniza√ß√£o de encodings  
                - ‚úì Tratamento de valores inconsistentes  
                - ‚úì Registro de exce√ß√µes para auditoria  
                - ‚úì Padroniza√ß√£o de formatos e nomes

        3. **‚úÖ Pr√©-Exporta√ß√£o (Valida√ß√£o Final)**

            a) **‚úîÔ∏è Checklist obrigat√≥rio**:  
                - [ ] Verificar completude de campos cr√≠ticos  
                - [ ] Validar consist√™ncia de tipos e formatos  
                - [ ] Confirmar ader√™ncia a regras de neg√≥cio

            b) **üìã Documenta√ß√£o de Regras**:
            ```markdown
            | Campo       | Restri√ß√£o                       | Respons√°vel |
            |-------------|----------------------------------|-------------|
            | data_nasc   | deve ser <= data_atual - 18 anos| RH          |
            | flag_bin    | deve conter apenas 0 ou 1       | Engenharia  |
            ```
        """

        with st.spinner("Gerando an√°lise da IA..."):
            try:
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {
                            "role": "system", 
                            "content": "Voc√™ √© um especialista que transforma problemas de qualidade de dados em insights acion√°veis espec√≠ficos ao dom√≠nio analisado. Seja pr√°tico e direto."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content
                
                # Fun√ß√£o robusta para extrair se√ß√µes
                def extract_section(content, section_tag):
                    start_tag = f"[{section_tag}]"
                    end_tags = [f"[{tag}]" for tag in ["PROBLEMA IDENTIFICADO", "RECOMENDA√á√ïES", "MITIGA√á√ÉO"] if tag != section_tag]
                    
                    if start_tag in content:
                        section_content = content.split(start_tag)[1]
                        
                        # Encontra o pr√≥ximo marcador de se√ß√£o
                        end_positions = []
                        for tag in end_tags:
                            if tag in section_content:
                                end_positions.append(section_content.index(tag))
                        
                        if end_positions:
                            section_content = section_content[:min(end_positions)]
                        
                        return section_content.strip()
                    return f"Se√ß√£o {section_tag} n√£o encontrada na resposta da IA"

                # Extrai as se√ß√µes
                problema = extract_section(content, "PROBLEMA IDENTIFICADO")
                recomendacoes = extract_section(content, "RECOMENDA√á√ïES")
                mitigacao = extract_section(content, "MITIGA√á√ÉO")

                # Layout em tr√™s colunas
                st.markdown("""
                <style>
                    .analysis-card {
                        padding: 15px;
                        border-radius: 10px;
                        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
                        margin-bottom: 20px;
                        background: #dbebfa;  /* COR ALTERADA */
                        opacity: 0.7;        /* TRANSPAR√äNCIA ADICIONADA */
                        height: 500px;
                        overflow-y: auto;
                        color: black !important;
                    }
                    .card-title {
                        font-size: 1.2em;
                        font-weight: bold;
                        margin-bottom: 15px;
                        color: #2c3e50;
                        border-bottom: 2px solid #0d0c0c;
                        padding-bottom: 8px;
                    }
                </style>
                """, unsafe_allow_html=True)

                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"""
                    <div class="analysis-card">
                        <div class="card-title">üõë Problema Identificado</div>
                        {problema}
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="analysis-card">
                        <div class="card-title">‚öôÔ∏è Recomenda√ß√µes ETL</div>
                        {recomendacoes}
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    st.markdown(f"""
                    <div class="analysis-card">
                        <div class="card-title">üõ°Ô∏è Sugest√µes de Mitiga√ß√£o</div>
                        {mitigacao}
                    </div>
                    """, unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"Erro na gera√ß√£o da an√°lise: {str(e)}")
                st.error("Por favor, tente novamente. Se o problema persistir, verifique sua conex√£o com a API da OpenAI.")

    # Se√ß√£o 3: Data Profiling
    st.header("üìä Profiling Completo")

    # Gera e exibe o relat√≥rio
    with st.spinner("Gerando relat√≥rio de profiling..."):
        if len(df) > 100_000:
            st.warning("Usando amostra de 100k linhas para melhor performance")
            sample_df = df.sample(n=100000, random_state=42)
        else:
            sample_df = df
        
        profile = ProfileReport(
            sample_df,
            minimal=True,
            correlations={
                "pearson": {"calculate": True},
                "spearman": {"calculate": False},
                "kendall": {"calculate": False}
            }
        )
        
        # Exibe o relat√≥rio
        st.components.v1.html(profile.to_html(), height=800, scrolling=True)
        
        # Bot√£o de download
        with st.expander("üíæ Op√ß√µes de Download", expanded=False):
            # CSS para bot√µes lado a lado
            st.markdown("""
            <style>
            .download-row {
                display: flex;
                gap: 10px;
                margin-top: 10px;
            }
            .download-btn {
                flex: 1;
                background-color: white !important;
                border: 1px solid #008fcf !important;
                color: #008fcf !important;
                border-radius: 4px;
                padding: 8px;
                text-align: center;
                cursor: pointer;
                transition: all 0.2s;
            }
            .download-btn:hover {
                background-color: #f0f8ff !important;
            }
            /* Remove os bot√µes padr√£o do Streamlit */
            .stDownloadButton { display: none !important; }
            </style>
            """, unsafe_allow_html=True)
            
            # Criar arquivo tempor√°rio para o relat√≥rio
            with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp:
                profile.to_file(tmp.name)
                html_content = open(tmp.name, "rb").read()
            
            # Criar arquivo tempor√°rio para os dados
            csv_content = df.to_csv(index=False).encode('utf-8')
            
            # Layout dos bot√µes - √öNICA implementa√ß√£o necess√°ria
            st.markdown("""
            <div class="download-row">
                <a href="data:text/html;base64,{b64_html}" download="profile_report.html" class="download-btn">
                    üì• Relat√≥rio (HTML)
                </a>
                <a href="data:text/csv;base64,{b64_csv}" download="dados_analisados.csv" class="download-btn">
                    üìä Dados (CSV)
                </a>
            </div>
            """.format(
                b64_html=base64.b64encode(html_content).decode(),
                b64_csv=base64.b64encode(csv_content).decode()
            ), unsafe_allow_html=True)

    # Se√ß√£o 4: Recomenda√ß√µes T√©cnicas
    st.header("üõ†Ô∏è Recomenda√ß√µes para Qualidade de Dados")

    # Criando abas para cada tipo de problema
    tab_comp, tab_uni, tab_cons, tab_int, tab_prec = st.tabs([
        "Completude", "Unicidade", "Consist√™ncia", "Integridade", "Precis√£o"
    ])

    with tab_comp:
        if scores["Completude"] <= 3:
            st.warning("**Problema Detectado**: Valores ausentes")
            st.markdown("""
            **O que significa?**  
            Colunas com valores nulos/em branco que podem prejudicar an√°lises.
            
            **Como resolver?**  
            - T√©cnicas de imputa√ß√£o:
            ```python
            # Preencher com m√©dia (colunas num√©ricas)
            df['coluna'].fillna(df['coluna'].mean(), inplace=True)
            
            # Preencher com moda (colunas categ√≥ricas)
            df['coluna'].fillna(df['coluna'].mode()[0], inplace=True)
            ```
            - Coleta adicional dos dados faltantes
            - Exclus√£o se n√£o forem cr√≠ticos (`df.dropna()`)
            """)
        else:
            st.success("‚úÖ Dados completos - Sem problemas significativos")

    with tab_uni:
        if scores["Unicidade"] <= 3:
            st.warning("**Problema Detectado**: Dados duplicados")
            st.markdown("""
            **O que significa?**  
            Registros id√™nticos que podem distorcer an√°lises estat√≠sticas.
            
            **Como resolver?**  
            ```python
            # Identificar duplicatas
            duplicates = df[df.duplicated(keep=False)]
            
            # Remover duplicatas (mantendo a primeira ocorr√™ncia)
            df.drop_duplicates(inplace=True)
            ```
            **Quando manter?**  
            Se forem registros v√°lidos (ex: vendas do mesmo produto para o mesmo cliente em datas diferentes)
            """)
        else:
            st.success("‚úÖ Dados √∫nicos - Sem duplicatas problem√°ticas")

    with tab_cons:
        if scores["Consist√™ncia"] <= 3:
            st.warning("**Problema Detectado**: Inconsist√™ncia de tipos")
            st.markdown("""
            **O que significa?**  
            Dados armazenados em formatos incorretos (ex: n√∫meros como texto).
            
            **Como corrigir?**  
            ```python
            # Converter tipos
            df['coluna'] = pd.to_numeric(df['coluna'], errors='coerce')  # Para n√∫meros
            df['coluna'] = pd.to_datetime(df['coluna'], errors='coerce') # Para datas
            ```
            **Impacto:**  
            C√°lculos estat√≠sticos falham quando tipos est√£o inconsistentes.
            """)
        else:
            st.success("‚úÖ Tipos consistentes - Dados bem formatados")

    with tab_int:
        if scores["Integridade"] <= 3:
            st.warning("**Problema Detectado**: Problemas de integridade")
            st.markdown("""
            **O que significa?**  
            Valores que violam regras de formato ou sem√¢ntica:
            
            - **C√≥digos inv√°lidos**: CPF/CNPJ/CEP com tamanho errado  
            - **Telefones**: N√∫mero incorreto de d√≠gitos  
            - **IDs/C√≥digos**: Tamanhos inconsistentes  
            - **Bin√°rios**: Valores diferentes de 0/1  
            - **N√∫meros negativos**: Onde n√£o s√£o permitidos  
            - **Datas**: Futuras em campos hist√≥ricos  

            **Como verificar manualmente:**  
            ```python
            # Verificar telefones (10 ou 11 d√≠gitos)
            df['telefone'].str.replace(r'\D', '', regex=True).str.len().unique()
            
            # Verificar CEP (8 d√≠gitos)
            df['cep'].str.replace(r'\D', '', regex=True).str.len().unique()
            
            # Verificar IDs (tamanho consistente)
            df['id'].astype(str).str.len().unique()
            
            # Verificar bin√°rios
            df['flag_binaria'].unique()  # Deve retornar apenas [0, 1]
            ```

            **Solu√ß√µes recomendadas:**  
            1. Para **c√≥digos mal formatados**:
            ```python
            # Padronizar CPF (123.456.789-09)
            df['cpf'] = df['cpf'].str.replace(r'(\d{3})(\d{3})(\d{3})(\d{2})', 
                                            r'\1.\2.\3-\4', regex=True)
            ```
            
            2. Para **valores bin√°rios inv√°lidos**:
            ```python
            df['flag'] = df['flag'].apply(lambda x: 1 if x > 0 else 0)
            ```
            
            3. Para **IDs inconsistentes**:
            ```python
            # Preencher com zeros √† esquerda
            df['id'] = df['id'].astype(str).str.zfill(10)  # 10 d√≠gitos
            ```
            """)
        else:
            st.success("""
            ‚úÖ Integridade validada - Todos os crit√©rios:
            - C√≥digos (CPF/CNPJ/CEP/Telefone) com formatos corretos  
            - IDs/C√≥digos com tamanhos consistentes  
            - Vari√°veis bin√°rias contendo apenas 0/1  
            - Sem valores negativos indevidos  
            """)

    with tab_prec:
        if scores["Precis√£o"] <= 3:
            st.warning("**Problema Detectado**: Outliers suspeitos")
            st.markdown("""
            **O que significa?**  
            Valores extremos que podem ser erros ou casos leg√≠timos.
            
            **Como identificar?**  
            ```python
            # M√©todo IQR
            Q1 = df['coluna'].quantile(0.25)
            Q3 = df['coluna'].quantile(0.75)
            IQR = Q3 - Q1
            outliers = df[(df['coluna'] < (Q1 - 1.5*IQR)) | (df['coluna'] > (Q3 + 1.5*IQR))]
            ```
            **A√ß√µes:**  
            - Verificar se s√£o erros de medi√ß√£o/digita√ß√£o  
            - Manter se forem casos v√°lidos (ex: clientes premium)
            """)
        else:
            st.success("‚úÖ Dados precisos - Sem outliers problem√°ticos")

    # Adicionando dicas gerais
    st.markdown("---")
    with st.expander("üìö Recursos Adicionais"):
        st.markdown("""
        - [Pandas: Tratamento de Dados Faltantes](https://pandas.pydata.org/docs/user_guide/missing_data.html)  
        - [SciKit-Learn: Imputa√ß√£o Avan√ßada](https://scikit-learn.org/stable/modules/impute.html)  
        - [Artigo: Outliers Detection](https://medium.com/@gabrielpbreis/outliers-como-definir-detectar-e-tratar-parte-1-50bf8e5e229a)
        """)

    # Rodap√©
    st.markdown("---")
    st.caption("Desenvolvido com Streamlit, ydata-profiling e OpenAI API ‚Ä¢ [Como contribuir?](https://github.com/daniell-santana/data-quality-profiling)")
